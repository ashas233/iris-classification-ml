# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y5QUANf-CiZpqNUMM2ziqcSqNdRq71-2
"""

!pip install -q ucimlrepo

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from ucimlrepo import fetch_ucirepo

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

iris = fetch_ucirepo(id=53)


X = iris.data.features
y = iris.data.targets

df = X.copy()
df['species'] = y


print("First 5 rows:\n", df.head())
print("\nClass distribution:\n", df['species'].value_counts())
print("\nSummary:\n", df.describe())

# Step 3: Load the Iris dataset using ucimlrepo
iris = fetch_ucirepo(id=53)

# Extract features and targets
X = iris.data.features
y = iris.data.targets

# Combine into one DataFrame for analysis
df = X.copy()
df['species'] = y

# Explore the dataset
print("First 5 rows:\n", df.head())
print("\nClass distribution:\n", df['species'].value_counts())
print("\nSummary:\n", df.describe())

# Step 4: Visualizations
sns.pairplot(df, hue='species')
plt.suptitle("Pair Plot by Species", y=1.02)
plt.show()

sns.heatmap(df.drop('species', axis=1).corr(), annot=True)
plt.title("Feature Correlation Heatmap")
plt.show()

# Step 5: Encode categorical labels
le = LabelEncoder()
df['species'] = le.fit_transform(df['species'])  # Convert to 0, 1, 2

# Split into features and target
X = df.drop('species', axis=1)
y = df['species']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 6A: Train Logistic Regression
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)
lr_preds = lr_model.predict(X_test)

# Evaluate
print("ðŸ“˜ Logistic Regression Accuracy:", accuracy_score(y_test, lr_preds))
print(classification_report(y_test, lr_preds))

sns.heatmap(confusion_matrix(y_test, lr_preds), annot=True, fmt='d', cmap='Blues')
plt.title("Logistic Regression Confusion Matrix")
plt.show()

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
knn_preds = knn_model.predict(X_test)

#print("ðŸ“— KNN Accuracy:", accuracy_score(y_test, knn_preds))
print(classification_report(y_test, knn_preds))

sns.heatmap(confusion_matrix(y_test, knn_preds), annot=True, fmt='d', cmap='Greens')
plt.title("KNN Confusion Matrix")
plt.show()

# Step 7: Tune K for KNN
accuracies = []
k_range = range(1, 21)

for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    acc = accuracy_score(y_test, knn.predict(X_test))
    accuracies.append(acc)

plt.plot(k_range, accuracies, marker='o')
plt.title("KNN Accuracy for Different K Values")
plt.xlabel("K")
plt.ylabel("Accuracy")
plt.xticks(k_range)
plt.grid(True)
plt.show()